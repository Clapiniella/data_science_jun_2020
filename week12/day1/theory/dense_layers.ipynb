{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.4 64-bit",
   "display_name": "Python 3.6.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5c4d2f1fdcd3716c7a5eea90ad07be30193490dd4e63617705244f5fd89ea793"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate?hl=es"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo\n",
    "\n",
    "# Las entradas van a tener 784 dimensiones en forma de vector (28x28)\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "# Primera capa de la red, con 64 neuronas y usando ReLu\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "# Segunda capa de la red, con 64 neuronas y usando ReLu\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "# La salida de la red con 10 neuronas porque estamos usando un algoritmo de clasificación de 10\n",
    "# Softmax \n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos y cogemos el conjunto de train, val y test\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fit model on training data\nEpoch 1/3\n782/782 [==============================] - 1s 769us/step - loss: 0.0306 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.1141 - val_sparse_categorical_accuracy: 0.9728\nEpoch 2/3\n782/782 [==============================] - 1s 835us/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.1119 - val_sparse_categorical_accuracy: 0.9749\nEpoch 3/3\n782/782 [==============================] - 1s 737us/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9749\n"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=3,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'loss': [0.030558396130800247, 0.02677304670214653, 0.024406464770436287],\n 'sparse_categorical_accuracy': [0.9905999898910522,\n  0.9918400049209595,\n  0.9927200078964233],\n 'val_loss': [0.11413111537694931, 0.11189764738082886, 0.115412637591362],\n 'val_sparse_categorical_accuracy': [0.9728000164031982,\n  0.9749000072479248,\n  0.9749000072479248]}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Podemos ver el histórico que ha ocurrido cogiendo el mejor de cada epoch\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Evaluate on test data\n79/79 [==============================] - 0s 480us/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9761\ntest loss, test acc: [0.10779914259910583, 0.9761000275611877]\n"
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Generate predictions for 3 samples\npredictions shape: (1, 10)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[3.65250401e-17, 5.26780876e-13, 1.56983548e-09, 3.55513912e-08,\n        6.67656979e-17, 1.15736447e-14, 1.05629485e-23, 1.00000000e+00,\n        2.64343170e-12, 1.32329746e-11]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:1])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Generate predictions for 3 samples\npredictions shape: (3, 10)\nImage 0 : 7\nImage 1 : 2\nImage 2 : 1\n"
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "for i,image_predicted in enumerate(predictions):\n",
    "    print(\"Image\",i,\":\", image_predicted.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}