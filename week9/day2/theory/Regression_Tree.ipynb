{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599561550730",
   "display_name": "Python 3.6.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   year  month  day  week  temp_2  temp_1  average  actual  forecast_noaa  \\\n0  2016      1    1   Fri      45      45     45.6      45             43   \n1  2016      1    2   Sat      44      45     45.7      44             41   \n2  2016      1    3   Sun      45      44     45.8      41             43   \n3  2016      1    4   Mon      44      41     45.9      40             44   \n4  2016      1    5  Tues      41      40     46.0      44             46   \n\n   forecast_acc  forecast_under  friend  \n0            50              44      29  \n1            50              44      61  \n2            46              47      56  \n3            48              46      53  \n4            46              46      41  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>week</th>\n      <th>temp_2</th>\n      <th>temp_1</th>\n      <th>average</th>\n      <th>actual</th>\n      <th>forecast_noaa</th>\n      <th>forecast_acc</th>\n      <th>forecast_under</th>\n      <th>friend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Fri</td>\n      <td>45</td>\n      <td>45</td>\n      <td>45.6</td>\n      <td>45</td>\n      <td>43</td>\n      <td>50</td>\n      <td>44</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Sat</td>\n      <td>44</td>\n      <td>45</td>\n      <td>45.7</td>\n      <td>44</td>\n      <td>41</td>\n      <td>50</td>\n      <td>44</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Sun</td>\n      <td>45</td>\n      <td>44</td>\n      <td>45.8</td>\n      <td>41</td>\n      <td>43</td>\n      <td>46</td>\n      <td>47</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>4</td>\n      <td>Mon</td>\n      <td>44</td>\n      <td>41</td>\n      <td>45.9</td>\n      <td>40</td>\n      <td>44</td>\n      <td>48</td>\n      <td>46</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Tues</td>\n      <td>41</td>\n      <td>40</td>\n      <td>46.0</td>\n      <td>44</td>\n      <td>46</td>\n      <td>46</td>\n      <td>46</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "# Read in data and display first 5 rows\n",
    "features = pd.read_csv('../data/temps.csv')\n",
    "# Actual column is the target\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   average  actual  forecast_noaa  forecast_acc  forecast_under  friend  \\\n0     45.6      45             43            50              44      29   \n1     45.7      44             41            50              44      61   \n2     45.8      41             43            46              47      56   \n3     45.9      40             44            48              46      53   \n4     46.0      44             46            46              46      41   \n\n   week_Fri  week_Mon  week_Sat  week_Sun  week_Thurs  week_Tues  week_Wed  \n0         1         0         0         0           0          0         0  \n1         0         0         1         0           0          0         0  \n2         0         0         0         1           0          0         0  \n3         0         1         0         0           0          0         0  \n4         0         0         0         0           0          1         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>average</th>\n      <th>actual</th>\n      <th>forecast_noaa</th>\n      <th>forecast_acc</th>\n      <th>forecast_under</th>\n      <th>friend</th>\n      <th>week_Fri</th>\n      <th>week_Mon</th>\n      <th>week_Sat</th>\n      <th>week_Sun</th>\n      <th>week_Thurs</th>\n      <th>week_Tues</th>\n      <th>week_Wed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45.6</td>\n      <td>45</td>\n      <td>43</td>\n      <td>50</td>\n      <td>44</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45.7</td>\n      <td>44</td>\n      <td>41</td>\n      <td>50</td>\n      <td>44</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45.8</td>\n      <td>41</td>\n      <td>43</td>\n      <td>46</td>\n      <td>47</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45.9</td>\n      <td>40</td>\n      <td>44</td>\n      <td>48</td>\n      <td>46</td>\n      <td>53</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46.0</td>\n      <td>44</td>\n      <td>46</td>\n      <td>46</td>\n      <td>46</td>\n      <td>41</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(features)\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "features.iloc[:,5:].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['actual'])\n",
    "# Remove the labels from the features \n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('actual', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2.016e+03, 1.000e+00, 1.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.000e+00, 2.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.000e+00, 3.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       ...,\n       [2.016e+03, 1.200e+01, 2.900e+01, ..., 1.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.200e+01, 3.000e+01, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.200e+01, 3.100e+01, ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(348,)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Features Shape: (261, 17)\nTraining Labels Shape: (261,)\nTesting Features Shape: (87, 17)\nTesting Labels Shape: (87,)\n"
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n                      max_features='auto', max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                      warm_start=False)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "# n_estimators: The number of trees in the forest.\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean Absolute Error: 3.87 degrees.\n"
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "48 - 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-6bd191bbbbc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;36m48\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;36m45\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "48 -- 100\n",
    "45 -- X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "93.75"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "(45 * 100) / 48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 93.93 %.\n"
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape) \n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'Z:/Data_Science/Software/Graphviz/bin/'\n",
    "os.environ[\"PATH\"] += os.pathsep + 'Z:\\\\Data_Science\\\\Software\\\\Graphviz\\\\bin\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "#graph.write_png('tree.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Big](big.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit depth of tree to 3 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "#graph.write_png('small_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cogemos un nodo para cuando la temp_1 sea menor o igual a 59.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En orden: \n",
    "\n",
    "1. La condición de ese nodo\n",
    "2. MSE\n",
    "3. Número de ejemplos del dataset que cumplen la condición\n",
    "4. Valor de la predicción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small](small.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2.016e+03, 1.000e+00, 1.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.000e+00, 2.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.000e+00, 3.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       ...,\n       [2.016e+03, 1.200e+01, 2.900e+01, ..., 1.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.200e+01, 3.000e+01, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [2.016e+03, 1.200e+01, 3.100e+01, ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Variable: temp_1               Importance: 0.66\nVariable: average              Importance: 0.15\nVariable: forecast_noaa        Importance: 0.05\nVariable: forecast_acc         Importance: 0.03\nVariable: day                  Importance: 0.02\nVariable: temp_2               Importance: 0.02\nVariable: forecast_under       Importance: 0.02\nVariable: friend               Importance: 0.02\nVariable: month                Importance: 0.01\nVariable: year                 Importance: 0.0\nVariable: week_Fri             Importance: 0.0\nVariable: week_Mon             Importance: 0.0\nVariable: week_Sat             Importance: 0.0\nVariable: week_Sun             Importance: 0.0\nVariable: week_Thurs           Importance: 0.0\nVariable: week_Tues            Importance: 0.0\nVariable: week_Wed             Importance: 0.0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None]"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean Absolute Error: 3.92 degrees.\nAccuracy: 93.76 %.\n"
    }
   ],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "# Extract the two most important features\n",
    "important_indices = [feature_list.index('temp_1'), feature_list.index('average')]\n",
    "train_important = train_features[:, important_indices]\n",
    "test_important = test_features[:, important_indices]\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions and determine the error\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "errors = abs(predictions - test_labels)\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = np.mean(100 * (errors / test_labels))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA: Principal Component Analysis"
   ]
  }
 ]
}